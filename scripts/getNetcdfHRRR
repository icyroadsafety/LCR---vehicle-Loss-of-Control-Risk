#!/usr/bin/env python
import os, sys, errno, time, argparse, re, calendar, itertools as it
import multiprocessing as mp
# from joblib import Parallel, delayed
from os import path as path
from time import gmtime, mktime
import datetime
from datetime import date, timedelta
import glob
import re
import ftplib
import pytz
# from icecream import ic
#----------------------------------------------------------------------
#
fRemoteFileList_6=["a-6hour-hrrr-bfp-archive.shtml",  "a-6hour-hrrr-bfp.shtml", "a-6hour-hrrr-lcr-archive.shtml",  "a-6hour-hrrr-lcr.shtml", "a-last-run-time.shtml" ]
fRemoteFileList_24=["a-24hour-hrrr-bfp-archive.shtml",  "a-24hour-hrrr-bfp.shtml", "a-24hour-hrrr-lcr-archive.shtml",  "a-24hour-hrrr-lcr.shtml", "a-24last-run-time.shtml"]
fRemoteFileList_kml = ["a-6hour-hrrr-lcr-kml.shtml", "a-6hour-hrrr-bfp-kml.shtml","a-24hour-hrrr-lcr-kml.shtml", "a-24hour-hrrr-bfp-kml.shtml"]

rHourList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]
fcHourList = [6, 12, 18, 24, 30, 36, 42, 48, 54,60,66, 72]
gfsTimeDelay = 300 # minutes after initial time before grib2 becomes available.

DEBUG=False

__prog__ = os.path.basename(__file__)

# looking for the root directory of scripts - this is lcrBase
lcrBase= os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

lcrLogBase =  path.join(lcrBase, "log")
logFile = path.join(lcrLogBase, "hrrr-download.log")
log=open(logFile,"a")



lcrBinPath = "scripts"
lcrPngPath = "png"
gfsPath = "hrrr_nc_data"
scratchPath = "scratch"





nomadsServer = "http://nomads.ncep.noaa.gov:80"
hrrrRemotePath = "/dods/hrrr"




bVerbose=0

##############################################################################################################
def doUpload(fList,type=None,overWrite=False):
    
    fListRemote =[]
    
    try:
      # danrobinson@ftp3.ftptoyoursite.com:/www.icyroadsafety.com/web/content/lcr/forecast
      session = ftplib.FTP('ftp3.ftptoyoursite.com','danrobinson','YXL@icY!VZsM526d')
      session.cwd('/www.icyroadsafety.com/web/content/lcr/forecast')
    except BaseException as exception:
      logWrite(exception)
      return 0


    if ( type and not overWrite ): 
      try:
        fListRemote=session.nlst("*."+type)
      except ftplib.error_temp as e:                    
          # File of .type not found on remote.nb HTTP error is 450
          if e.args[0].startswith('450'):
            pass
          else:
            raise e
      else:
        fListRemote.sort()


    # fList=glob.glob(lcrPngPath+"/*[0-9]*.png")
    cnt=0;

    for rFile in fList:
      rClientFile=os.path.basename(rFile)
      if( overWrite == False and  rClientFile in fListRemote):
         continue

      try:
        ncfile = open(rFile,'rb')                  # file to send
        session.storbinary('STOR '+ rClientFile , ncfile)     # send the file
        ncfile.close()                                    # close file and FTP
      except BaseException as exception:
        logWrite(exception)
        session.quit()
        return cnt

      cnt+=1



    session.quit()

    # logWrite("doUpload() - uploaded %d files."% cnt)
    return cnt


def prepUpload_6( Model, runDate ):

    fList=[]

    runDateStr=runDate.strftime("%Y%m%d%H")



    lcrPngList=glob.glob(lcrPngPath+"/hrrr_sfc.r{0}_[0-9]_[0-9]_lcr.png".format(runDateStr))
    bfpPngList=glob.glob(lcrPngPath+"/hrrr_sfc.r{0}_[0-9]_[0-9]_bfp.png".format(runDateStr))


    # remember shtml file can get deleted 
    if SingleToFile("a-6hour-hrrr-lcr.shtml",'<a href="/lcr/forecast/{0}"><img src="/lcr/forecast/{0}" style="width:100%;"></a>', lcrPngList, True):
        fList.append( lcrPngList[0] )        

    # remember shtml file can get deleted 
    if SingleToFile("a-6hour-hrrr-bfp.shtml",'<a href="/lcr/forecast/{0}"><img src="/lcr/forecast/{0}" style="width:100%;"></a>', bfpPngList, True):
        fList.append( bfpPngList[0] )        


    # run date USA style month/day/year?
    with open(path.join(scratchPath,"a-last-run-time.shtml"), "w" ) as f:
        f.write(runDate.strftime("%Hz %m/%d/%Y"))


    Yesterday=datetime.datetime.now() - timedelta(days=1)

    fList+= globToFile("/hrrr_sfc.r[0-9]*_[0-9]_[0-9]_lcr.png", "a-6hour-hrrr-lcr-archive.shtml", '<a href="/lcr/forecast/{}">{}z HRRR</a><br>\n', Yesterday )
    fList+= globToFile("/hrrr_sfc.r[0-9]*_[0-9]_[0-9]_bfp.png", "a-6hour-hrrr-bfp-archive.shtml", '<a href="/lcr/forecast/{}">{}z HRRR</a><br>\n', Yesterday)
    


    return fList


def prepUpload_24( Model, runDate ):

    fList=[]

    runDateStr=runDate.strftime("%Y%m%d%H")


    lcrPngList=glob.glob(lcrPngPath+"/hrrr_sfc.r{0}_[0-9]*_[0-9][0-9]_lcr.png".format(runDateStr))
    bfpPngList=glob.glob(lcrPngPath+"/hrrr_sfc.r{0}_[0-9]*_[0-9][0-9]_bfp.png".format(runDateStr))

    # remember shtml file can get deleted 
    if SingleToFile("a-24hour-hrrr-lcr.shtml",'<a href="/lcr/forecast/{0}"><img src="/lcr/forecast/{0}" style="width:100%;"></a>', lcrPngList, True):
        fList.append( lcrPngList[0] )        

    # remember shtml file can get deleted 
    if SingleToFile("a-24hour-hrrr-bfp.shtml",'<a href="/lcr/forecast/{0}"><img src="/lcr/forecast/{0}" style="width:100%;"></a>', bfpPngList, True):
        fList.append( bfpPngList[0] )        

    # run date USA style month/day/year?
    with open(path.join(scratchPath,"a-24last-run-time.shtml"), "w" ) as f:
        f.write(runDate.strftime("%Hz %m/%d/%Y"))

    # 4 files in 24 hours so go back six days ?
    BackDate=datetime.datetime.now() - timedelta(days=6)

    fList+= globToFile("/hrrr_sfc.r[0-9]*_[0-9]_[0-9][0-9]_lcr.png", "a-24hour-hrrr-lcr-archive.shtml", '<a href="/lcr/forecast/{}">{}z HRRR</a><br>\n', BackDate )
    fList+= globToFile("/hrrr_sfc.r[0-9]*_[0-9]_[0-9][0-9]_bfp.png", "a-24hour-hrrr-bfp-archive.shtml", '<a href="/lcr/forecast/{}">{}z HRRR</a><br>\n', BackDate)



    return fList

def prepUpload_6_kml( Model, runDate ):
    fList = []

    runDateStr=runDate.strftime("%Y%m%d%H")
    kmlPath = path.join(lcrBase,"kml")

    if not os.path.exists(kmlPath):
        return fList

    

    lcrKmlList = glob.glob(kmlPath+"/hrrr_sfc.r{0}_[0-9]_[0-9]_lcr.kml".format(runDateStr))
    bfpKmlList = glob.glob(kmlPath+"/hrrr_sfc.r{0}_[0-9]_[0-9]_bfp.kml".format(runDateStr))

    # remember shtml file can get deleted 
    if SingleToFile("a-6hour-hrrr-lcr-kml.shtml",'<a href="/lcr/forecast/{0}">Download 6 Hour LCR KML</a>', lcrKmlList, True):
        fList.append( lcrKmlList[0] )        

    if SingleToFile("a-6hour-hrrr-bfp-kml.shtml",'<a href="/lcr/forecast/{0}">Download 6 Hour BFP KML</a>', bfpKmlList, True):
        fList.append( bfpKmlList[0] )


    return fList



def prepUpload_24_kml( Model,runDate ):
    # deal with kml files 
    fList = []
    runDateStr=runDate.strftime("%Y%m%d%H")
    
    kmlPath = "kml"

    if not os.path.exists(kmlPath):
        return fList
    
    lcrKmlList = glob.glob(kmlPath+"/hrrr_sfc.r{0}_[0-9]_[0-9][0-9]_lcr.kml".format(runDateStr))
    bfpKmlList = glob.glob(kmlPath+"/hrrr_sfc.r{0}_[0-9]_[0-9][0-9]_bfp.kml".format(runDateStr))
  
    
    if SingleToFile("a-24hour-hrrr-lcr-kml.shtml",'<a href="/lcr/forecast/{0}">Download 24 Hour LCR KML</a>', lcrKmlList, True):
        fList.append( lcrKmlList[0] )        

    if SingleToFile("a-24hour-hrrr-bfp-kml.shtml",'<a href="/lcr/forecast/{0}">Download 24 Hour BFP KML</a>', bfpKmlList, True):
        fList.append( bfpKmlList[0] )
    

    return fList

    # if clobber then htmlfile is deleted if fList is empty
def SingleToFile( htmlFile, TextSkeleton, fList, bClobber=False):

    fl = path.join(scratchPath, htmlFile)

    if len(fList) == 0 :
        if os.path.exists(fl) and bClobber:
            os.remove(fl)
        return False  

    
    with open(fl, "w" ) as ArchiveFileHandle:
        ArchiveFileHandle.write( TextSkeleton.format( os.path.basename(fList[0]) ) )
    
    return True




def globToFile(globPattern, ArchiveFile, TextSkeleton, BackDate):
    fList = []
    fl = path.join(scratchPath, ArchiveFile)
    ArchiveFileHandle=open(fl, "w" )
    PngList=glob.glob(lcrPngPath+globPattern)
    if len(PngList) >0 :
        
        PngList.sort( reverse=True )

        for Png in PngList:
            PngBase=os.path.basename(Png)
            [model, dt]=mkmodeldate(PngBase)
            if( dt> BackDate ):
                fList.append(Png)
                ArchiveFileHandle.write( TextSkeleton.format( PngBase, dt.strftime("%Y/%m/%d %H") ))
        
    ArchiveFileHandle.close()
    # remember ArchiveFile gets deleted if glob is empty or no files younger than BackDate 
    if os.path.getsize(fl) == 0:
        os.remove(fl)
    
    return fList


def Upload_kml(model, runDate):
    
    cnt=0
    
    fkmlList=[]
    fhtmlList=[] 

    fkmlList += prepUpload_6_kml(model,runDate)
    fkmlList += prepUpload_24_kml(model,runDate)
    
    if len(fkmlList)==0:
        logWrite("Upload_kml(): No lcr/bfp kml files with Date {}".format(runDate))
        return 0

    for fl in fRemoteFileList_kml:
        fl=os.path.join(  scratchPath,fl )
        if(  os.path.exists(fl) ):
            fhtmlList.append(fl)

    if len(fhtmlList)==0:
        return 0

    if DEBUG:
       print("Upload_kml(): files to upload:")
       for fl in fkmlList:
           print(fl)
       for fl in fhtmlList:
           print(fl)  

       return len(fkmlList)+len(fhtmlList)   

    # really upload files
    if (cnt:=doUpload(fkmlList ,"kml", False)) == 0:
        return 0

    logWrite(f"Upload_kmk() - uploaded {cnt} png files.")

    cnt_s=doUpload(fhtmlList ,"shtml", True)
    logWrite(f"Upload_kml() - uploaded {cnt_s} shtml files.")
    return cnt+cnt_s 

def Upload_png(model, runDate):
    cnt=0

    fpngList=[]
    fhtmlList=[] 

    fpngList += prepUpload_6(model,runDate)
    fpngList += prepUpload_24(model,runDate)
    
    if len(fpngList)==0:
        logWrite("Upload_png(): No lcr/bfp png files with Date {}".format(runDate))
        return 0

    for fl in fRemoteFileList_6+ fRemoteFileList_24:
        fl=os.path.join(  scratchPath,fl )
        if(  os.path.exists(fl) ):
            fhtmlList.append(fl)

    if len(fhtmlList)==0:
        return 0

    if DEBUG:
       print("Upload_png(): files to upload:")
       for fl in fpngList:
           print(fl)
       for fl in fhtmlList:
           print(fl)  

       return len(fpngList)+len(fhtmlList)   

    # really upload files
    if (cnt:=doUpload(fpngList ,"png", False)) == 0:
        return 0

    logWrite(f"Upload_png() - uploaded {cnt} png files.")

    cnt_s=doUpload(fhtmlList ,"shtml", True)
    logWrite(f"Upload_png() - uploaded {cnt_s} shtml files.")
    return cnt+cnt_s 


def Upload(model, runDate):
    cnt=0

    cnt=Upload_kml(model, runDate)
    cnt+=Upload_png(model, runDate)

    return cnt


def Upload_old(model, runDate):
    
    Debug=True
    cnt=0
    scratchPath=path.join(lcrBase,"scratch")

    if ( model == None or runDate == None ):
        return 0


    fList=prepUpload_6(model,runDate)
    fList+= prepUpload_24(model,runDate)
    if ( len(fList)==0):
        logWrite("prepUpload: No lcr/bfp images with Date {}".format(runDate))
        return 0

    # don't overwrite if png exists
    if (Debug):
        cnt=len(fList)
        print(fList);
    else:
        cnt=doUpload(fList,"png", False)

    logWrite("Upload() - uploaded %d png files."% cnt)

    # cnt=1

    # if at least 1 new image has been uploaded then also upload the a*.shtml files
    if ( cnt == 0):
       return 0

    fList=[]

    for fl in fRemoteFileList_6+ fRemoteFileList_24:
        fl=os.path.join(  scratchPath,fl )
        if(  os.path.exists(fl) ):
            fList.append(fl)

    if (Debug):
        cnt=len(fList)
        print(fList)
    else:
        cnt=doUpload(fList,"shtml", True)


    logWrite("Upload() - uploaded %d shtml files."% cnt)

    return cnt

def mkdate(datestr):
    return datetime.datetime.strptime(datestr, '%Y-%m-%d')

def mklongdate(datestr):
    return datetime.datetime.strptime(datestr, '%Y%m%d%H')

def mkmodeldate(ncFile):

    if( ncFile == None ):
        return [None, None]

    ncFileBase = os.path.basename(ncFile)

    idx=ncFileBase.find("_")
    Model=ncFileBase[0:idx]

    idx=ncFileBase.find(".")
    #tmp=baseFileName[idx+2:idx+12]
    # dt=datetime.datetime.strptime(ncFileBase[idx+2:idx+12],"%Y%m%d%H")
    dt=mklongdate(ncFileBase[idx+2:idx+12])

    return [Model, dt ]
def getGFSTimeABS(gfsStart, fcHour):
    gfsTimeABS = gfsStart + timedelta(hours=fcHour)
    return gfsTimeABS

def getGFSTimeEpoch(gfsDateTime):
#    print gfsDateTime
    gfsTimeEpoch = calendar.timegm(gfsDateTime.timetuple())
    return gfsTimeEpoch

#####
# This one is the epoch used to distinguish seemingly duplicate file names; NOT to be confused with GFSTimeEpoch.
def epochVal(gH):
    if (gH < 4): gH += 24
    return (((gH -4) / 6) * 6 + 4)

#####
# Return the most-recent GFS Date-Hour of grib2 file that *should* be available,
# or return GFS Date-Hour specified by --rdate --rhour, rounded to earlier run if needed ...
def latestGFSStart(dt=None, hr=None):
    if (dt == None): dt = datetime.fromtimestamp(mktime(gmtime()))
    if (hr == None): hr = dt.hour
    ### @note: this works assuming gfsTimeDelay < 6 hours ...
    gfsStartDate = datetime.datetime.now() - timedelta(minutes=gfsTimeDelay)
    gfsStartHour = max([h for h in rHourList if h <= gfsStartDate.hour])
    gfsStart = datetime.datetime.combine(gfsStartDate, datetime.time(gfsStartHour))
    pStart = datetime.datetime.combine(dt, datetime.time(hr))
    if (pStart < gfsStart):
        return pStart
    else:
        return gfsStart


def logWrite(sMessage):
     d1=datetime.datetime.now()
     d1.replace(microsecond=0)         

     
     sText="%s(%s): %s"%(__prog__,d1.strftime("%m-%d %H:%M"), sMessage)
     bVerbose and print(sText)

     log.write(sText+"\n")       
  
       
# return full filename of  latest download
def latestGoodDownload(Model):
    # flist=glob.glob(gfsPath+"/hrrr_sfc.r??????????.nc")
    fList=glob.glob(gfsPath+"/hrrr_sfc.r[0-9]*.nc")
    fList.sort()

    return fList.pop();
    
    
    if( len(fList) >0):
       fname=os.path.basename(fList.pop());
        # name of the form gfs.0p50.2015040500.nc     
       # we just want the date+hour    
       Ts=fname[-13:-3]
       # lDate=datetime.datetime.utcfromtimestamp(float(sT))
       lDate=datetime.datetime.strptime(Ts,"%Y%m%d%H")
       return lDate  
    else:
       return None;       

def listTodayYesterday():
     listDates=[]
     Today=datetime.datetime.today();
     Today=Today.replace(hour=0,minute=0,second=0,microsecond=0)
     Yesterday=Today-timedelta(days=1)
     Dbyday=Today-timedelta(days=2)      

     for rH in rHourList:  
       listDates.append( Today+timedelta(hours=rH) )    
       listDates.append(Yesterday+timedelta(hours=rH) );
       listDates.append(Dbyday+timedelta(hours=rH) );

     listDates.sort()
     listDates.reverse()    
     # print listDates
     return listDates;   

# finds latest live gfs data on the server
# does this by check for existance of a .das file 
def getRemoteContent(iDate,ext,numProc=1):
  Debug=False
  sDate=iDate.strftime("%Y%m%d"); # string of date
  sHour=iDate.strftime("%H");     # string of hour  

  fullRemotePath=nomadsServer+hrrrRemotePath+"/hrrr"+sDate+"/hrrr_sfc.t"+sHour+"z";
  # only append ext if not nc
  if( ext != "nc" ):
    fullRemotePath += "."+ext;

  # fullLocalPath=gfsPath+"/gfs.0p50."+sDate+sHour+"."+ext;
  epochSeconds=time.mktime(iDate.timetuple())
  
  LocalPath= "{}/hrrr_sfc.r{}{}.{}".format(gfsPath,sDate,sHour, ext)
  
  # this string is used by ncl to rebase the time coo-rdinates
  # from "days since 1-1-1" to "hours since filetimestamp
  time_units2="hours since {0}".format(iDate.strftime("%Y-%m-%d %H:00"))

  time_opt="small"
  # temporary test for download whole forecast at 0/6/12/18 hours - nb at these hours fcHour goes to  49 hours
  if ( int(sHour) % 6 ==0 ):
      time_opt="all"

  if(Debug): time_opt="tst"

  shellCMD= path.join(lcrBinPath,"getNetcdfData.sh")   
  
  fullCMD = "{0} {1} {2} {3} {4} {5}".format(shellCMD, fullRemotePath, LocalPath,ext, time_opt, "hrrr")

  ret=os.system(fullCMD);
  ret=os.waitstatus_to_exitcode(ret)
  
  if(ret==0 and os.path.isfile(LocalPath) ):
      return LocalPath
    # return os.path.basename(fullLocalPath);

  else:
    return None;   

# rebase the lon co-ordinate var from 0.0/355.0  to -180/179.5
def rebaseLocalContent(fullName):

   # fullName=gfsPath+"/"+localName
   shellCMD= lcrBinPath+"/lon360TO180.sh"
   shellCMD+= " "+ fullName
   ret=1

   if( os.path.isfile(fullName)):
      if (os.system(shellCMD)==0): 
        logWrite("Have rebased the lon coordinate of the file  {0} ".format(fullName))                        
   else:
      logWrite("unable to locate the file {0} ".format(fullName))                        

  
   return 0;

def Caption (ncFile, srtIndex, endIndex):

    # time step in hours - should be getting this from the ncFile
    step=1;

    [Product,fcDate]=mkmodeldate(ncFile)
    Product=Product.upper();


    srtDate=fcDate.astimezone(pytz.timezone('US/Central')) + datetime.timedelta(hours=srtIndex*step)
    endDate=fcDate.astimezone(pytz.timezone('US/Central')) + datetime.timedelta(hours=endIndex*step)


     # LCR maximum values through 10PM CDT Tuesday, December 5, 2023.  Generated from the 19z HRRR
    # BFP+ maximum values through 10PM CDT Tuesday, December 5, 2023.  Generated from the 19z HRRR
    title=" maximum values through {}  Generated from {}z {}.".format( endDate.strftime("%l%p CST %A, %B %e, %Y"),   fcDate.strftime("%H"), Product  )
    
    return title


def doDownloadCustom(pModel, pDate, bSkipDownload):


    fileUserBase="{0}_sfc.r{1}.nc".format(pModel,pDate.strftime("%Y%m%d%H") )
    # remember this is a relative path
    fileUser=os.path.join(gfsPath,fileUserBase)

    if( os.path.exists(fileUser)):
        logWrite( "doDownloadCustom(): Requested file %s already exists."% (fileUserBase))
        return fileUser
    elif (bSkipDownload):
        logWrite( "doDownloadCustom(): Requested file %s doesn't exist locally."% (fileUserBase))
        return None

    # if here than try download
    dasfileName=getRemoteContent(pDate,"das")
    if (not dasfileName ):
        logWrite("doDownloadCustom(): Unable to download the user requested {0} file.".format(dasfileName) )
        return None

    os.remove(dasfileName)
    logWrite("doDownloadCustom(): downloading user file {0} ".format(fileUserBase))
    fileName=getRemoteContent(pDate,"nc");

    if( fileName ):
        logWrite("doDownloadCustom(): downloaded user file {0} ".format(fileUserBase))
        return fileUser
    else:
        logWrite("doDownloadCustom(): Unable to download the user requested {0} file.".format(fileUserBase) )
        return None

    return None



# does it all - checks the local and remote directories directory
def doDownload(Model="hrrr", bSkipDownload=False ):

    dasfileName=None
    dateServer=None
    dateLastGood=None
    fileLastGood=None

    # remember this is a relative path
    fList=glob.glob(gfsPath+"/hrrr_sfc.r[0-9]*.nc")
    if (len(fList) ):
        fList.sort()
        fileLastGood=fList.pop()
        [m, dateLastGood]=mkmodeldate(fileLastGood)


    if(bSkipDownload):
        return fileLastGood


    # listDates is in reverse order by date
    listDates=listTodayYesterday();

    # find first good date
    for dt in listDates:
       dasfileName=getRemoteContent(dt,"das")
       if ( dasfileName ):
         dateServer=dt;
         os.remove(dasfileName);
         break;

       
    logWrite( "/***************** Starting hrrr_sfc download script ***********************/")     
    if(dateLastGood):   
      logWrite( "Last good download %s"% (dateLastGood.strftime("%Y/%m/%d %H:%M")) )               
    
    if(dateServer):
       logWrite( "Latest hrrr_sfc file on server is dated %s"% (dateServer.strftime("%Y/%m/%d %H:%M")) )    
    else:
       logWrite("No hrrr_sfc content from the last 48 hours found on server." )          
       return None


    if( dateLastGood and dateLastGood == dateServer ):       
       logWrite("The latest hrrr_sfc  data has already been downloaded." )            
       return fileLastGood
    elif(dateLastGood and  dateLastGood > dateServer  ):      
       logWrite("Paradoxically the latest local data is more recent than that on the server." )            
       return fileLastGood

    # if we are here then we need to download latest
    fileName=getRemoteContent(dateServer,"nc");    
    if( fileName): 
       logWrite("Just downloaded {0} the latest data.".format(os.path.basename(fileName)))
       return fileName
    else:
       logWrite("Unable to download {0} the latest data.".format(os.path.basename(dasfileName)))
       return None

    return None

def doLcr(ncFile, srtIndex, endIndex):


    Title =  Caption(ncFile, srtIndex, endIndex)
    # title has spaces so quote
    Title="'"+ Title+"'" 
    shellCMD= path.join(lcrBinPath,"doLCR.sh")
   
    # This script rquires the lcrBase directory - So that absolute file paths can be used
    # for calls to lcrmap.py and bfpmap.py
    fullCMD = "{0} {1} {2} {3} {4} {5}".format(shellCMD, lcrBase, ncFile, srtIndex, endIndex, Title);

    
    ncBase=path.basename(ncFile)
    ret=os.system(fullCMD);
    ret=os.waitstatus_to_exitcode(ret)      

    match ret:
       case 0:
         logWrite( "Post processing of file %s successful."% ncBase);
       case 1:
         logWrite( "Post processing of file %s failed. lcr.nco failed."% ncBase);
       case 2:
         logWrite( "Post processing of file %s failed. ncwa step failed."% ncBase);
       case 3:
         logWrite( "Post processing of file %s failed. lcrmap step failed."% ncBase);
       case 4:
         logWrite( "Post processing of file %s failed. bfpmap step failed."% ncBase);
       case 5:
         logWrite( "Post processing of file %s failed."% ncBase);
       case 8:
         logWrite( "Post processing of file %s failed. kml file creation steps failed."% ncBase);
       case 10:
         logWrite( "Images from  %s already exist."% ncBase);

    if ret == 0 or ret == 10:
       return 1

    return 0;

##############################################################################################################
# usgage examples
# to download, process and upload - the latest data  from the command line
# getNecdfHRRR -v
# to get a specific data set from the NOMADS server use --rdata
# getNetcdfHRRR -v --rdate=2023121510
# to just process a specific data set
#  getNetcdfHRRR -v   --skip-download --skip-upload --rdate=2023121510
# to just upload the latest images to the website
# getNetcdfHRRR -v   --skip-download  --skip-processing
# to process and upload a specific data set
# getNetcdfHRRR -v   --skip-download  --rdate=2023121410
##############################################################################################################
__version__ = "1.00"
parser = argparse.ArgumentParser(prog=__prog__,
    description='Download Netcdf Files from NOAA NOMADS server. Make Map images. Upload to web-site.',
    formatter_class=lambda prog: argparse.HelpFormatter(prog,max_help_position=42,width=120))
parser.add_argument('--background', action='store_true', help='launch downloads in background (daemonize) ')
parser.add_argument('--dryrun', action='store_true', help="show command stream but don't execute it")
parser.add_argument('-f', '--fchour', nargs='+', type=int, choices=fcHourList, help='limit downloading to specified forecast-hour(s)')
parser.add_argument('-j', '--jobs', nargs='?', type=int, default=4, help='number of paralel processes')
parser.add_argument('-q', '--quiet', action='store_true', help='silent as the grave')
parser.add_argument('--rdate', nargs='?', type=mklongdate, help='Specify with a date/time an explict nc file to download. format e.g "2024112912"')
parser.add_argument('--rhour', nargs='?', type=int, choices=rHourList, help='download grib2 files fpr specified run-hour(s)')
parser.add_argument('--skip-download', action='store_true', help='assume data already downloaded; just launch the render-and-slice process.')
parser.add_argument('--skip-processing', action='store_true', help='do NOT launch the render-and-slice process after download.')
parser.add_argument('--skip-upload', action='store_true', help='do NOT upload to the server using ftp.')
parser.add_argument('-v', '--verbose', action='count', default=0, help='blather-on ...')
parser.add_argument('-V', '--version', action='version', version='%(prog)s  (version {0})'.format(__version__), help='print version info.')
##############################################################################################################
if __name__ == '__main__':
    os.nice(20) # Be VERY nice!

    args = parser.parse_args()

#    print(args)
    bDaemon = args.background
    bDryRun = args.dryrun
    pfcHour = args.fchour or fcHourList
    parallelJobCount = args.jobs
    bQuiet = args.quiet
    pDate = args.rdate
    # if (pDate == None): pDate = gmtime()
    # rDate = datetime.datetime.fromtimestamp(mktime(pDate))
    # rHour = args.rhour
    # if (rHour == None): rHour = rDate.hour
    bSkipProcessing = args.skip_processing
    bSkipDownload = args.skip_download
    bSkipUpload = args.skip_upload
    bVerbose = args.verbose
    if (bVerbose): bQuiet = False
    ncUserFile=None
    pModel="hrrr"

    
    # all files directories kml, png, scratch, log, hrrr_nc_data are relative to lcrBase, the project root
    # and shell scripts are executed from there too
    os.chdir(lcrBase)

    # a user specified file
    if(pDate):
        ncUserFile=doDownloadCustom(pModel,pDate,bSkipDownload)
    else:
        ncUserFile=doDownload(pModel, bSkipDownload)
        [m, pDate]=mkmodeldate(ncUserFile)

    # should have a log message from doDownload
    if(not ncUserFile):
        sys.exit(1)

    # hard coded indices temporary hack    
    if not bSkipProcessing and ncUserFile:
        # process hourly
        cret = doLcr(ncUserFile, 2, 9)
        # run 24 hour model four times a day
        if pDate.hour in [0, 6, 12, 18]:
            cret=doLcr(ncUserFile,2,25)

    if(not bSkipUpload):
        #cret=Upload(pModel,pDate)
        doUpload(['hello.zzz'], '*.zzz', False)
        
    sys.exit(0);

